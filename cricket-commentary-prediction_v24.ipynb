{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing TrainingData and TestData csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('../Data/CCC_TrainingData.csv')\n",
    "df_ts = pd.read_csv('../Data/CCC_TestData.csv')\n",
    "\n",
    "df_tr1 = df_tr[['Target','Commentary']].copy()\n",
    "df_tr1.replace(to_replace={'Dot':0, 'Run_Bw_Wickets':1, 'Boundary':2, 'Wicket':3}, inplace=True)\n",
    "\n",
    "df_ts1 = df_ts[['Commentary']].copy()\n",
    "\n",
    "df_tr1.to_csv('../Data/TrainingData.csv', index=False)\n",
    "df_ts1.to_csv('../Data/TestData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datapath = '/kaggle/input/cricket-commentary/'\n",
    "\n",
    "datapath = '../Data/'\n",
    "datafile = 'TrainingData.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the dataset for Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_csv(datapath, datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating Language Model, with AWD_LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.7)\n",
    "#learn_lm = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.5) less accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding optimum learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_lm.lr_find(start_lr=1e-8, end_lr=1e2)\n",
    "#learn_lm.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training using fit one cycle approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_lm.model_dir='/kaggle/working/'\n",
    "\n",
    "learn_lm.model_dir='../Output/'\n",
    "\n",
    "# Run one epoch with lower layers \n",
    "learn_lm.fit_one_cycle(1, 1e-1) #better accuracy version 14\n",
    "\n",
    "learn_lm.unfreeze()\n",
    "\n",
    "#learn_lm.fit_one_cycle(20, slice(1e-2/10, 1e-2))\n",
    "# version 21\n",
    "#learn_lm.fit_one_cycle(8, slice(1e-2/10, 1e-2))\n",
    "\n",
    "#version 24\n",
    "# Run for many epochs with all layers unfrozen\n",
    "learn_lm.fit_one_cycle(9, slice(1e-2/10, 1e-2))\n",
    "\n",
    "#Version 27 , Using Callbacks\n",
    "#learn_lm.fit_one_cycle(1, 1e-3, moms=(0.8,0.7), callbacks=[ShowGraph(learn_lm),\n",
    "#                                                              SaveModelCallback(learn_lm,monitor='accuracy',mode='max')]) #9 is best 2.517068\t2.853009\t0.405768\t\n",
    "\n",
    "\n",
    "learn_lm.recorder.plot_metrics()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 21 update\n",
    "#learn_lm.model_dir='/kaggle/working/'\n",
    "# Run one epoch with lower layers \n",
    "#learn_lm.fit_one_cycle(cyc_len=1, max_lr=1e-3, moms=(0.8, 0.7))\n",
    "\n",
    "# Run for many epochs with all layers unfrozen\n",
    "#learn_lm.unfreeze()\n",
    "#learn_lm.fit_one_cycle(cyc_len=20, max_lr=1e-3, moms=(0.8, 0.7))\n",
    "\n",
    "#Version 21\n",
    "#learn_lm.recorder.plot_losses()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.predict(\"the yorker gone \", n_words=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save_encoder('lm_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bulding the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = TextClasDataBunch.from_csv(datapath, datafile, vocab=data_lm.train_ds.vocab, bs=32) #Tried multiple batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_clas = text_classifier_learner(data_clas, drop_mult=0.7,arch=AWD_LSTM) #Better accuracy with 0.7 dropout rate\n",
    "\n",
    "#learn_clas = text_classifier_learner(data_clas, drop_mult=0.5,arch=AWD_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_clas.load_encoder('/kaggle/working/lm_enc')\n",
    "\n",
    "learn_clas.load_encoder('../Output/lm_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling class imbalance of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../input/cricket-commentary/TrainingData.csv')\n",
    "df = pd.read_csv('../Data/TrainingData.csv')\n",
    "\n",
    "labelcounts = df.groupby([\"Target\"]).size()\n",
    "label_sum = len(df[\"Target\"])\n",
    "class_imbalance = [(count/label_sum) for count in labelcounts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_balance = [(1-count/label_sum) for count in labelcounts]\n",
    "loss_weights = torch.FloatTensor(weights_balance).cuda()\n",
    "learn_clas.crit = partial(F.cross_entropy, weight=loss_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding learning rate for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Learning rate for classifier\n",
    "#learn_clas.model_dir='/kaggle/working/'\n",
    "#learn_clas.freeze()\n",
    "#learn_clas.lr_find(start_lr=1e-8, end_lr=1e2)\n",
    "#learn_clas.recorder.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 20 update\n",
    "#learn_clas.freeze()\n",
    "#learn_clas.fit_one_cycle(cyc_len=1, max_lr=1e-3, moms=(0.8, 0.7))\n",
    "\n",
    "#learn_clas.freeze_to(-2)\n",
    "#learn_clas.fit_one_cycle(1, slice(1e-4,1e-2), moms=(0.8,0.7))\n",
    "\n",
    "#learn_clas.freeze_to(-3)\n",
    "#learn_clas.fit_one_cycle(1, slice(1e-5,5e-3), moms=(0.8,0.7))\n",
    "\n",
    "#learn_clas.unfreeze()\n",
    "#learn_clas.fit_one_cycle(5, slice(1e-5,1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 15\n",
    "#Training layers one by one\n",
    "learn_clas.freeze()\n",
    "learn_clas.fit_one_cycle(1, 1e-2)\n",
    "\n",
    "learn_clas.freeze_to(-2)\n",
    "learn_clas.fit_one_cycle(1, slice(1e-3/10, 1e-3))\n",
    "\n",
    "learn_clas.freeze_to(-3)\n",
    "learn_clas.fit_one_cycle(1, slice(1e-3/10, 1e-3))\n",
    "\n",
    "learn_clas.unfreeze()\n",
    "#learn_clas.fit_one_cycle(20, slice(1e-3/10, 1e-3))\n",
    "#best\n",
    "#learn_clas.fit_one_cycle(11, slice(1e-3/10, 1e-3))\n",
    "\n",
    "#version 24\n",
    "learn_clas.fit_one_cycle(13, slice(1e-3/10, 1e-3)) # 13 is best 0.174861\t0.310772\t0.895312\n",
    "\n",
    "##Using callbacks to find best accuracy\n",
    "#learn_clas.fit_one_cycle(1, slice(1e-3/10, 1e-3), callbacks=[ShowGraph(learn_clas),\n",
    "#                                                            SaveModelCallback(learn_clas,monitor='accuracy',mode='max')]) \n",
    "\n",
    "\n",
    "# 11 Epoch 0.174883\t0.339358\t0.888621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best accuracy - commenting for now\n",
    "#learn_clas.fit_one_cycle(20, 1e-2)\n",
    "#learn_clas.unfreeze()\n",
    "#learn_clas.fit_one_cycle(20, slice(1e-3/10, 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/kaggle/working/sub.pkl'\n",
    "\n",
    "path = '../Output/sub.pkl'\n",
    "\n",
    "path = Path(path)\n",
    "#learn_clas.model_dir='/kaggle/working/'\n",
    "learn_clas.export(path)\n",
    "\n",
    "learn_clas.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = pd.read_csv('../input/testdata/TestData.csv')\n",
    "test_df = pd.read_csv('../Data/TestData.csv')\n",
    "\n",
    "learn_clas.data.add_test(test_df['Commentary'])\n",
    "\n",
    "prob_preds = learn_clas.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
    "\n",
    "#labels = np.argmax(prob_preds, 1)\n",
    "#test_df['category'] = labels\n",
    "#test_df.to_csv('/kaggle/working/submission.csv')\n",
    "\n",
    "labels = np.argmax(prob_preds[0],1)\n",
    "df_f = pd.DataFrame(labels)\n",
    "df_f.replace(to_replace={0:'Dot', 1:'Run_Bw_Wickets', 2:'Boundary', 3:'Wicket'}, inplace=True)\n",
    "\n",
    "df_f.reset_index(inplace=True)\n",
    "df_f.columns=['ID','Target']\n",
    "\n",
    "#df_f.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "df_f.to_csv('../Output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv('../Output/submission.csv')\n",
    "dfb = pd.read_csv('../Data/CCC_TestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(dfa, dfb, on=('ID'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = ['Boundary','Run_Bw_Wickets']\n",
    "c2 = ['Boundary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a Rule to utilize Over Run Total feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['Target'] = np.where((df_merge.Target.isin(c1)) & (df_merge['Over_Run_Total'] ==0), 'Dot',df_merge['Target']) \n",
    "df_merge['Target'] = np.where((df_merge.Target.isin(c2)) & (df_merge['Over_Run_Total'] < 4), 'Run_Bw_Wickets',df_merge['Target']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_merge[['ID','Target']].copy()\n",
    "df_sub.to_csv('../Output/final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
